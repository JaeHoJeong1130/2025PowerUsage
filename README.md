# 2025PowerUsage - 전력 사용량 예측 대회

**대회 링크**: https://dacon.io/competitions/official/236531/overview/description

## 프로젝트 개요

이 프로젝트는 2024년 6월부터 8월까지의 건물별 전력 사용량 데이터를 활용하여 향후 7일간의 전력 사용량을 예측하는 머신러닝 대회입니다. 100개 건물의 시간별 전력 소비량을 예측하는 것이 목표입니다.

## 데이터 분석 및 전처리 과정

### 1. 데이터 탐색 및 시각화
- **electro_00_00_01_img.py**: 건물별 전력 사용량 시각화 도구 개발
- **electro_00_00_02_img_nan.py**: 이상치 탐지 및 처리 로직 구현
  - 일별 최저 전력량 평균의 80%를 임계값으로 설정하여 이상치 제거
  - 시각적 확인을 위한 그래프 저장 기능

### 2. 이상치 처리 및 데이터 정제
- **electro_00_00_일사이상치.py**: 일사량 데이터의 이상치 처리
- 결측치 처리: '-' 값을 0으로 변환
- 건물 정보 데이터의 숫자형 변환 및 원-핫 인코딩

## 피처 엔지니어링

### 시간 관련 피처
- 월, 일, 시간, 요일 추출
- 공휴일 정보 (2024-06-06, 2024-08-15)
- 주말 여부 판단
- 시간의 주기성을 반영한 sin/cos 변환
- MMDDHH 형태의 시간 조합 피처

### 기상 관련 피처
- 불쾌지수 계산: `9/5 * 기온 - 0.55 * (1 - 습도/100) * (9/5 * 기온 - 26) + 32`
- 기온, 습도, 풍속, 강수량의 롤링 통계 (3, 6, 12, 24시간)
- 일조량, 일사량 예측 모델 구축

### 건물 특성 피처
- 연면적, 냉방면적
- 태양광용량, ESS저장용량, PCS용량
- 건물유형별 원-핫 인코딩
- 건물 그룹핑을 통한 유사 건물 분류

## 모델링 접근법

### 1. 단일 모델 실험
- **electro_01_GRU.py**: Seq2Seq GRU 모델로 시계열 예측
  - 14일 입력, 7일 출력 구조
  - 인코더-디코더 아키텍처
  - 로그 변환을 통한 정규화

### 2. XGBoost 기반 모델
- **electro_02_01_XGB_grid.py**: GridSearchCV를 통한 하이퍼파라미터 튜닝
- **electro_03_XGB.py**: 건물별 개별 모델 학습
  - EarlyStopping 적용
  - 피처 중요도 기반 선택
  - 로그 변환 및 역변환

### 3. 다중 모델 앙상블
- **electro_05_X_L_C.py**: XGBoost, LightGBM, CatBoost 3개 모델 앙상블
  - 각 모델별 하이퍼파라미터 최적화
  - 검증 성능 기반 가중치 계산
  - 피처 중요도 기반 피처 선택

### 4. 고급 최적화 기법
- **electro_09_X_C_optu_kfold.py**: Optuna를 활용한 베이지안 최적화
  - K-Fold 교차 검증
  - SMAPE 평가 지표 사용
  - XGBoost와 CatBoost 앙상블

### 5. 스태킹 앙상블
- **electro_11_X_C_optu_kfold_FI_Stacking.py**: 
  - 피처 중요도 기반 피처 선택
  - Ridge 회귀를 메타 모델로 사용
  - 2단계 스태킹 구조

- **electro_13_stacking.py**: 최종 스태킹 모델
  - Optuna를 통한 하이퍼파라미터 최적화
  - 5-Fold 교차 검증
  - RidgeCV를 통한 메타 모델 최적화

## 핵심 기술적 노력

### 1. 데이터 품질 개선
- 이상치 탐지 및 제거 알고리즘 개발
- 일사량/일조량 예측 모델 구축으로 결측치 보완
- 건물별 특성을 고려한 그룹핑

### 2. 피처 엔지니어링
- 시간의 주기성을 반영한 삼각함수 변환
- 기상 데이터의 롤링 통계 생성
- 불쾌지수 등 도메인 지식 활용

### 3. 모델 최적화
- Optuna를 활용한 자동 하이퍼파라미터 튜닝
- EarlyStopping으로 과적합 방지
- 피처 중요도 기반 피처 선택

### 4. 앙상블 기법
- 다중 모델의 가중 평균
- 스태킹을 통한 메타 학습
- 검증 성능 기반 동적 가중치 계산

## 최종 모델 구조

1. **Base Models**: XGBoost, CatBoost
2. **Meta Model**: Ridge 회귀
3. **평가 지표**: SMAPE (Symmetric Mean Absolute Percentage Error)
4. **검증 방법**: 5-Fold 교차 검증
5. **최적화**: Optuna 베이지안 최적화

## 결과 및 성과

- 체계적인 데이터 전처리 파이프라인 구축
- 다양한 머신러닝 기법의 실험적 적용
- 도메인 지식을 활용한 피처 엔지니어링
- 고급 앙상블 기법을 통한 성능 향상

시계열 예측, 앙상블 기법, 하이퍼파라미터 최적화 등 머신러닝의 다양한 기법을 종합적으로 학습하고 적용할 수 있었습니다.
