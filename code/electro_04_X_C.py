import pandas as pd
import numpy as np
import xgboost as xgb
import catboost as cb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
from tqdm import tqdm
import datetime
import random
import os

# --- ê²½ë¡œ ì„¤ì • ë° ì‹œë“œ ê³ ì • ---
path = "/home/jjh/Project/_data/dacon/electro/"
w_path = "/home/jjh/Project/_data/dacon/electro/wei/"
s_path = "/home/jjh/Project/_data/dacon/electro/sub/"
os.makedirs(w_path, exist_ok=True)
warnings.filterwarnings('ignore')

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)

seed_everything(42)
print("ëœë¤ ì‹œë“œë¥¼ 42ë¡œ ê³ ì •í–ˆìŠµë‹ˆë‹¤.")

# --- ë°ì´í„° ë¡œë”©, ì „ì²˜ë¦¬, í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ê¸°ì¡´ê³¼ ë™ì¼) ---
print("\n1 & 2. ë°ì´í„° ë¡œë”©, ì „ì²˜ë¦¬, í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìˆ˜í–‰...")
train_df = pd.read_csv(path + 'train.csv', encoding='utf-8')
test_df = pd.read_csv(path + 'test.csv', encoding='utf-8')
building_info_df = pd.read_csv(path + 'building_info.csv', encoding='utf-8')
sample_submission_df = pd.read_csv(path + 'sample_submission.csv', encoding='utf-8')

building_info_df.replace('-', '0', inplace=True)
building_info_df['íƒœì–‘ê´‘ìš©ëŸ‰(kW)'] = building_info_df['íƒœì–‘ê´‘ìš©ëŸ‰(kW)'].astype(float)
building_info_df['ESSì €ì¥ìš©ëŸ‰(kWh)'] = building_info_df['ESSì €ì¥ìš©ëŸ‰(kWh)'].astype(float)
building_info_df['PCSìš©ëŸ‰(kW)'] = building_info_df['PCSìš©ëŸ‰(kW)'].astype(float)
building_info_df = pd.get_dummies(building_info_df, columns=['ê±´ë¬¼ìœ í˜•'], drop_first=True)
train_df = pd.merge(train_df, building_info_df, on='ê±´ë¬¼ë²ˆí˜¸')
test_df = pd.merge(test_df, building_info_df, on='ê±´ë¬¼ë²ˆí˜¸')

def feature_engineering(df):
    df['ì¼ì‹œ'] = pd.to_datetime(df['ì¼ì‹œ'])
    df['month'] = df['ì¼ì‹œ'].dt.month; df['day'] = df['ì¼ì‹œ'].dt.day; df['hour'] = df['ì¼ì‹œ'].dt.hour
    df['dayofweek'] = df['ì¼ì‹œ'].dt.dayofweek
    df['MMDDHH'] = df['month'].astype(str).str.zfill(2) + df['day'].astype(str).str.zfill(2) + df['hour'].astype(str).str.zfill(2)
    df['MMDDHH'] = df['MMDDHH'].astype(int)
    holidays = [pd.to_datetime('2024-06-06'), pd.to_datetime('2024-08-15')]
    df['holiday'] = df['ì¼ì‹œ'].dt.date.isin([d.date() for d in holidays]).astype(int)
    df['discomfort_index'] = 9/5 * df['ê¸°ì˜¨(Â°C)'] - 0.55 * (1 - df['ìŠµë„(%)']/100) * (9/5 * df['ê¸°ì˜¨(Â°C)'] - 26) + 32
    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)
    return df
train_df = feature_engineering(train_df); test_df = feature_engineering(test_df)

train_df['ì¼ì‹œ'] = pd.to_datetime(train_df['ì¼ì‹œ'])
last_date = train_df['ì¼ì‹œ'].max()
validation_start_date = last_date - pd.Timedelta(days=7)
train_final_df = train_df[train_df['ì¼ì‹œ'] < validation_start_date].copy()
valid_final_df = train_df[train_df['ì¼ì‹œ'] >= validation_start_date].copy()
print(f"ìµœì¢… í›ˆë ¨ ë°ì´í„°: {train_final_df.shape}, ìµœì¢… ê²€ì¦ ë°ì´í„°: {valid_final_df.shape}")

sun_features = ['ê¸°ì˜¨(Â°C)', 'í’ì†(m/s)', 'ìŠµë„(%)', 'ê°•ìˆ˜ëŸ‰(mm)', 'sin_hour', 'cos_hour', 'dayofweek', 'month']
sun_targets = ['ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)']
train_sun = train_final_df.dropna(subset=sun_targets).copy()
for target in sun_targets:
    X_sun_train = train_sun[sun_features]; y_sun_train = train_sun[target]
    sun_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    sun_model.fit(X_sun_train, y_sun_train)
    for df in [test_df, valid_final_df]:
        X_sun_pred = df[sun_features]
        sun_predictions = sun_model.predict(X_sun_pred)
        sun_predictions[sun_predictions < 0] = 0
        df[target] = sun_predictions
print("ì „ì²˜ë¦¬ ì™„ë£Œ.")

# --- ëª¨ë¸ í•™ìŠµ, HPO, ì•™ìƒë¸” ë¡œì§ ---
print("\n3. ê±´ë¬¼ë³„ 2ê°œ ëª¨ë¸(XGB, CatBoost) GridSearchCV ë° ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œì‘...")
scaler = StandardScaler()
final_predictions = pd.DataFrame()
validation_predictions = pd.DataFrame()

# íŒŒë¼ë¯¸í„°
param_grids = {
    'xgb': {
        'learning_rate': np.round(np.arange(0.01, 0.1, 0.02), 2).tolist(),
        'max_depth': [5, 7, 9],
        'subsample': [0.7, 0.8, 0.9],
        'colsample_bytree': [0.7, 0.8, 0.9]
    },
    'catboost': {
        'learning_rate': [0.02, 0.05, 0.1],
        'depth': [6, 8, 10],
        'subsample': [0.7, 0.8],
        'l2_leaf_reg': [1, 3, 5] # L2 Regularization
    }
}
initial_features = [
    'ê¸°ì˜¨(Â°C)', 'ê°•ìˆ˜ëŸ‰(mm)', 'í’ì†(m/s)', 'ìŠµë„(%)', 'ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)',
    'ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)',
    'month', 'day', 'hour', 'dayofweek', 'MMDDHH', 'holiday',
    'discomfort_index', 'sin_hour', 'cos_hour'
]
initial_features += [col for col in building_info_df.columns if 'ê±´ë¬¼ìœ í˜•_' in col]

for building_num in tqdm(range(1, 101), desc="ì „ì²´ ê±´ë¬¼ í•™ìŠµ ì§„í–‰"):
    train_building = train_final_df[train_final_df['ê±´ë¬¼ë²ˆí˜¸'] == building_num].copy()
    test_building = test_df[test_df['ê±´ë¬¼ë²ˆí˜¸'] == building_num].copy()
    valid_building = valid_final_df[valid_final_df['ê±´ë¬¼ë²ˆí˜¸'] == building_num].copy()

    train_building.dropna(axis=1, inplace=True)
    current_features = [f for f in initial_features if f in train_building.columns]
    
    X = train_building[current_features]
    y = train_building['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
    
    current_features_in_X = list(X.columns)
    test_building = test_building[current_features_in_X]
    valid_building = valid_building[current_features_in_X]
    
    if X.empty:
        preds_test = np.zeros(len(test_building))
        building_submission = pd.DataFrame({'answer': preds_test})
        final_predictions = pd.concat([final_predictions, building_submission], ignore_index=True)
        preds_valid = np.zeros(len(valid_building))
        building_validation = pd.DataFrame({'answer': preds_valid})
        validation_predictions = pd.concat([validation_predictions, building_validation], ignore_index=True)
        continue

    X_scaled = scaler.fit_transform(X)
    X_test_scaled = scaler.transform(test_building)
    X_valid_scaled = scaler.transform(valid_building)
    y_log = np.log1p(y)
    
    test_preds_dict = {}
    valid_preds_dict = {}

    # [ìˆ˜ì •] lgbm ëª¨ë¸ ë£¨í”„ì—ì„œ ì œê±°
    for model_name in ['xgb', 'catboost']:
        print(f"\n--- ê±´ë¬¼ {building_num} / {model_name} ëª¨ë¸ HPO ì‹œì‘ ---")
        
        # [ìˆ˜ì •] GridSearchCV ìš© ëª¨ë¸ì—ëŠ” n_estimatorsë¥¼ ë‚®ê²Œ ì„¤ì •
        base_params = {'random_state': 42, 'n_estimators': 200}
        if model_name == 'xgb':
            model = xgb.XGBRegressor(objective='reg:squarederror', **base_params)
        else: # catboost
            model = cb.CatBoostRegressor(verbose=0, **base_params)
            
        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], scoring='neg_mean_absolute_error', cv=3, verbose=1, n_jobs=-1)
        grid_search.fit(X_scaled, y_log)
        
        best_params = grid_search.best_params_
        best_params['n_estimators'] = 1000 # ìµœì¢… ëª¨ë¸ì€ ë‚˜ë¬´ 1000ê°œë¡œ í•™ìŠµ
        
        X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_log, test_size=0.15, random_state=42)

        print(f"--- ê±´ë¬¼ {building_num} / {model_name} ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
        if model_name == 'xgb':
            es_xgb = xgb.callback.EarlyStopping(rounds = 400,metric_name = 'mae',data_name = 'validation_0',save_best = True,)
            final_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, **best_params, eval_metric='mae', callbacks = [es_xgb])
            final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)
            final_model.save_model(w_path + f'building_{building_num}_xgb_model.json')
            test_preds_log = final_model.predict(X_test_scaled, iteration_range=(0, final_model.best_iteration))
            valid_preds_log = final_model.predict(X_valid_scaled, iteration_range=(0, final_model.best_iteration))
        
        else: # catboost
            final_model = cb.CatBoostRegressor(random_state=42, **best_params, verbose=0)
            final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, use_best_model=True)
            final_model.save_model(w_path + f'building_{building_num}_cat_model.cbm')
            test_preds_log = final_model.predict(X_test_scaled)
            valid_preds_log = final_model.predict(X_valid_scaled)
        
        test_preds_dict[model_name] = np.expm1(test_preds_log)
        valid_preds_dict[model_name] = np.expm1(valid_preds_log)

    print(f"--- ê±´ë¬¼ {building_num} / ì•™ìƒë¸” ìˆ˜í–‰ ---")
    ensemble_test_preds = np.mean(list(test_preds_dict.values()), axis=0)
    ensemble_test_preds[ensemble_test_preds < 0] = 0
    
    ensemble_valid_preds = np.mean(list(valid_preds_dict.values()), axis=0)
    ensemble_valid_preds[ensemble_valid_preds < 0] = 0
    
    building_submission = pd.DataFrame({'answer': ensemble_test_preds})
    final_predictions = pd.concat([final_predictions, building_submission], ignore_index=True)

    building_validation = pd.DataFrame({'answer': ensemble_valid_preds})
    validation_predictions = pd.concat([validation_predictions, building_validation], ignore_index=True)


print("ëª¨ë“  ê±´ë¬¼ ëª¨ë¸ HPO ë° ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ.")

# --- 4. ìµœì¢… ìŠ¤ì½”ì–´ ê³„ì‚° ë° ì œì¶œ íŒŒì¼ ìƒì„± ---
print("\n4. ìµœì¢… ìŠ¤ì½”ì–´ ê³„ì‚° ë° ì œì¶œ íŒŒì¼ ìƒì„± ì‹œì‘...")

true_values = valid_final_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].values
predicted_values = validation_predictions['answer'].values
final_mae_score = mean_absolute_error(true_values, predicted_values)

print("="*60)
print(f"ğŸ† ìµœì¢… ë¡œì»¬ ê²€ì¦ ìŠ¤ì½”ì–´ (MAE): {final_mae_score:.4f}")
print("="*60)

sample_submission_df['answer'] = final_predictions['answer']
timestamp = datetime.datetime.now().strftime("%m%d_%H%M%S")
final_filename = s_path + f'submission_score_{final_mae_score:.4f}_{timestamp}.csv'
sample_submission_df.to_csv(final_filename, index=False)
print(f"ì œì¶œ íŒŒì¼ '{final_filename}' ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")